name: Every 5 minutes scrape

on:
  schedule:
    - cron:  '0 8 * * *'        # UTC; same as local schedule
  workflow_dispatch:            # manual “Run workflow” button in UI

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4          # fetch repo

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'           # keep in sync with your venv

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run full pipeline
        run: python -m scraper.selenium_scraper

      - name: Upload artefacts (optional)
        uses: actions/upload-artifact@v4
        with:
          name: dashboard-data
          path: |
            data/techinasia_jobs_*.csv
            data/charts/*.png

      # OPTIONAL — commit sanitised CSV back to repo
      - name: Commit & push cleaned data
        if: github.ref == 'refs/heads/main'
        run: |
          git config --global user.name  "gha-bot"
          git config --global user.email "gha@users.noreply.github.com"
          git add data/*.csv
          git commit -m "GH Action: update data (`date -u '+%Y-%m-%d %H:%M'`)" || echo "No changes"
          git push
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}  # auto-scoped token
